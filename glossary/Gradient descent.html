<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Gradient descent</title>
	<link rel="stylesheet" href="/assets/css/styles.css" />
</head>
<body>
<h1>Gradient descent</h1>

<h2 id="general-gradient-descent-algorithm">General gradient descent
algorithm</h2>
<p>Iteratively update the parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐱</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math>
by making small adjustment that decreases
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>𝐱</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\mathbf{x})</annotation></semantics></math>.</p>
<p>In particular, update
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝐱</mi><mo>←</mo><mi>𝐱</mi><mo>+</mo><mi>η</mi><mi>𝐯</mi></mrow><annotation encoding="application/x-tex">\mathbf{x} \leftarrow \mathbf{x} + \eta\mathbf{v}</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\eta &gt; 0</annotation></semantics></math>
is step size.</p>
<h2 id="gradient-descent-method">Gradient descent method</h2>
<p>Iteratively update the current estimate in the direction opposite the
gradient direction
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>l</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>−</mo><mi>α</mi><mfrac><mrow><mi>∂</mi><mi>J</mi></mrow><mrow><mi>∂</mi><mi>𝐱</mi></mrow></mfrac><msub><mo minsize="1.8" maxsize="1.8" stretchy="false" form="prefix">|</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>l</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></mtd></mtr></mtable></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}^{(l+1)}=\mathbf{x}^{(l)}-\alpha \frac{\partial J}{\partial \mathbf{x}}\Bigr|_{\substack{\mathbf{x}^{(l)}}}</annotation></semantics></math>
The solution depends on the initial condition. Reaches the local minimum
closest to the initial condition if the stepsize is chosen properly.</p>
<p>Yield global optimal if J is <a
href="Convex%20function.html">convex</a>, regardless initial solution</p>
<h2 id="gradient-descent-analysis">Gradient descent analysis</h2>
<p>Assume:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
is <a href="Convex%20function.html">convex</a></li>
<li><a href="Lipschitz%20function.html">Lipschitz function</a>: for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐱</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>∇</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>𝐱</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mn>2</mn></msub><mo>≤</mo><mi>G</mi></mrow><annotation encoding="application/x-tex">||\nabla f(\mathbf{x})||_2 \leq G</annotation></semantics></math></li>
<li>starting radius:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><msup><mi>𝐱</mi><mo>*</mo></msup><mo>−</mo><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mn>2</mn></msub><mo>≤</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">||\mathbf{x}^{*}-\mathbf{x}^{(0)}||_2 \leq R</annotation></semantics></math></li>
</ul>
<p>Gradient descent:</p>
<ul>
<li>choose number of steps
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math></li>
<li>starting point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathbf{x}^{(0)}</annotation></semantics></math>,
e.g.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mover><mn>0</mn><mo accent="true">→</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{x}^{(0)} = \vec{0}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>=</mo><mfrac><mi>R</mi><mrow><mi>G</mi><msqrt><mi>T</mi></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">\eta = \frac{R}{G \sqrt{T}}</annotation></semantics></math></li>
<li>for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">i=0,…,T</annotation></semantics></math>:
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>−</mo><mi>η</mi><mi>∇</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{x}^{(i+1)}=\mathbf{x}^{(i)}-\eta \nabla f(\mathbf{x}^{(i)})</annotation></semantics></math></li>
</ul></li>
<li>return
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>𝐱</mi><mo accent="true">̂</mo></mover><mo>=</mo><mo>arg</mo><msub><mo>min</mo><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></msub><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>𝐱</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\mathbf{x}} = \arg \min_{\mathbf{x}^{(i)}} f(\mathbf{x}^{(i)})</annotation></semantics></math></li>
</ul>
<p><a href="Gradient%20descent%20convergence%20bound.html">Gradient
descent convergence bound</a></p>
<hr />
<h2 id="gradient-descent-for-constrained-optimization">Gradient descent
for constrained optimization</h2>
<ul>
<li>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>=</mo><mo>=</mo><mfrac><mi>D</mi><mrow><mi>G</mi><msqrt><mi>T</mi></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">\eta==\frac{D}{G\sqrt{T}}</annotation></semantics></math></li>
<li>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mn>0</mn></msub><annotation encoding="application/x-tex">x_0</annotation></semantics></math>
be any point in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒦</mi><annotation encoding="application/x-tex">\mathcal{K}</annotation></semantics></math>.</li>
<li><strong>Repeat for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">i=0</annotation></semantics></math>
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math></strong></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>←</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>η</mi><mi>∇</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y_{i+1} \leftarrow x_i -\eta\nabla f(x_i)</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>←</mo></mrow><annotation encoding="application/x-tex">x_{i+1} \leftarrow</annotation></semantics></math>
Projection of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">y_{i+1}</annotation></semantics></math>
on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒦</mi><annotation encoding="application/x-tex">\mathcal{K}</annotation></semantics></math></li>
<li>At the end output
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>x</mi><mo accent="true">‾</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>T</mi></msubsup><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\bar{x}=\frac{1}{T} \sum_{i=0}^T x_i</annotation></semantics></math>.</li>
</ul>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math>
is the diameter for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒦</mi><annotation encoding="application/x-tex">\mathcal{K}</annotation></semantics></math>,
or if unconstrained, then simply an upper bound on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><msub><mi>x</mi><mn>0</mn></msub><mo>−</mo><msup><mi>x</mi><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow></mrow><annotation encoding="application/x-tex">||x_0 - x^*||</annotation></semantics></math>.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>
is an upper bund on the size of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>‘s
gradient, i.e.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>∇</mi><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mn>2</mn></msub><mo>≤</mo><mi>G</mi><mo>,</mo><mo>∀</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">||\nabla f(x)||_2 \leq G, \forall x</annotation></semantics></math>.</p>
<hr />
<p>See: <a href="Stochastic%20gradient%20descent.html">Stochastic gradient
descent</a>, <a href="Gradient.html">Gradient</a></p>
<hr />
<p>References:</p>
<ol type="1">
<li><a
href="https://www.chrismusco.com/amlds2023/notes/lecture06.html#Projected_Gradient_Descent">https://www.chrismusco.com/amlds2023/notes/lecture06.html#Projected_Gradient_Descent</a></li>
<li><a
href="https://www.cs.princeton.edu/courses/archive/fall18/cos521/Lectures/lec16.pdf">https://www.cs.princeton.edu/courses/archive/fall18/cos521/Lectures/lec16.pdf</a></li>
<li><a
href="https://en.wikipedia.org/wiki/Gradient_descent">https://en.wikipedia.org/wiki/Gradient_descent</a></li>
<li><a
href="https://www.stat.cmu.edu/~ryantibs/convexopt-F13/scribes/lec6.pdf">https://www.stat.cmu.edu/~ryantibs/convexopt-F13/scribes/lec6.pdf</a></li>
</ol>
</body>
</html>
